{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fed13c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09cb354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../ML Assignment/DATA/Dataset_FE2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0a7183",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis']=df['diagnosis'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "642d0486",
   "metadata": {},
   "outputs": [],
   "source": [
    "randlist=[1223, 91, 760, 1096, 670, 715, 373, 69, 538, 455]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e124e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = [1]*10\n",
    "test_array = [1]*10\n",
    "X_train= [1]*10\n",
    "X_test= [1]*10\n",
    "y_train= [1]*10\n",
    "y_test = [1]*10\n",
    "for i in range(10):\n",
    "    train_array[i] = df.sample(frac=0.67, random_state = randlist[i])\n",
    "    test_array[i] = df.drop(train_array[i].index)\n",
    "    trainData_Split = train_array[i].to_numpy()\n",
    "    testData_Split = test_array[i].to_numpy()\n",
    "    n_samples,n_features = trainData_Split.shape\n",
    "    n_features -= 1\n",
    "    X_train[i] = trainData_Split[:,1:]\n",
    "    y_train[i] = trainData_Split[:,0]\n",
    "    X_test[i] = testData_Split[:,1:]\n",
    "    y_test[i] = testData_Split[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc28b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, learning_rate = 0.01, num_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = num_iters\n",
    "        self.activation = self._step_function\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.n_iters):\n",
    "            for index,x_i in enumerate(X):\n",
    "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
    "                y_predicted = self.activation(linear_output)\n",
    "                \n",
    "                update = self.lr * (y[index] - y_predicted)\n",
    "                self.weights += update * x_i\n",
    "                self.bias += update\n",
    "                \n",
    "    \n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self.activation(linear_output)\n",
    "        return y_predicted\n",
    "    \n",
    "    def _step_function(self, x):\n",
    "        return np.where(x>=0, 1, 0)\n",
    "    \n",
    "    def _sigmoid_function(self, x):\n",
    "        sig_x = 1/(1+(np.exp(-x)).astype(float))\n",
    "        return np.where(sig_x>=0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80ba7e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMetrics(y_actual, y_predicted):\n",
    "    tp = np.sum((y_actual == 1) & (y_predicted == 1))\n",
    "    tn = np.sum((y_actual == 0) & (y_predicted == 0))\n",
    "    fp = np.sum((y_actual == 0) & (y_predicted == 1))        \n",
    "    fn = np.sum((y_actual == 1) & (y_predicted == 0)) \n",
    "    accuracy = np.sum(y_actual == y_predicted)/len(y_actual)\n",
    "    precision = tp/np.sum(tp+fp)\n",
    "    recall = tp/np.sum(tp+fn)\n",
    "    return 100*accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54298946",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [1]*10\n",
    "for i in range(10):\n",
    "    p[i] = Perceptron(learning_rate=0.1, num_iters=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6fcdbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    p[i].fit(X_train[i], y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8c546ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [1]*10\n",
    "for i in range(10):\n",
    "    predictions[i]=p[i].predict(X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bb056cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for test-train split 0\n",
      "96.27659574468085 0.9583333333333334 0.9452054794520548\n",
      "\n",
      "\n",
      "Metrics for test-train split 1\n",
      "96.27659574468085 0.9333333333333333 0.9722222222222222\n",
      "\n",
      "\n",
      "Metrics for test-train split 2\n",
      "96.80851063829788 0.9726027397260274 0.9466666666666667\n",
      "\n",
      "\n",
      "Metrics for test-train split 3\n",
      "95.74468085106383 0.9558823529411765 0.9285714285714286\n",
      "\n",
      "\n",
      "Metrics for test-train split 4\n",
      "95.2127659574468 0.927536231884058 0.9411764705882353\n",
      "\n",
      "\n",
      "Metrics for test-train split 5\n",
      "95.74468085106383 0.9333333333333333 0.958904109589041\n",
      "\n",
      "\n",
      "Metrics for test-train split 6\n",
      "94.68085106382979 0.8923076923076924 0.9508196721311475\n",
      "\n",
      "\n",
      "Metrics for test-train split 7\n",
      "95.74468085106383 0.9444444444444444 0.9444444444444444\n",
      "\n",
      "\n",
      "Metrics for test-train split 8\n",
      "95.74468085106383 0.9692307692307692 0.9130434782608695\n",
      "\n",
      "\n",
      "Metrics for test-train split 9\n",
      "97.87234042553192 0.9726027397260274 0.9726027397260274\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = [1]*10\n",
    "prec = [1]*10\n",
    "rec = [1]*10\n",
    "for i in range(10):\n",
    "    acc[i], prec[i], rec[i] = computeMetrics(y_test[i], predictions[i])\n",
    "    print(\"Metrics for test-train split {}\".format(i))\n",
    "    print(acc[i], prec[i], rec[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8d399b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy = 96.01063829787235 and Variance of Accuracy = 0.6931869624264365\n",
      "Mean Precision = 0.9459606970260197 and Variance of Precision = 0.0005751920004782246\n",
      "Mean Recall = 0.9473656711652139 and Variance of Recall = 0.00029830547292258647\n"
     ]
    }
   ],
   "source": [
    "acc = np.array(acc)\n",
    "prec = np.array(prec)\n",
    "rec = np.array(rec)\n",
    "\n",
    "print(\"Mean Accuracy = {} and Variance of Accuracy = {}\".format(np.mean(acc), np.var(acc)))\n",
    "print(\"Mean Precision = {} and Variance of Precision = {}\".format(np.mean(prec), np.var(prec)))\n",
    "print(\"Mean Recall = {} and Variance of Recall = {}\".format(np.mean(rec), np.var(rec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2588e947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
